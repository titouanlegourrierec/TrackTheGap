{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_driver() -> webdriver.Chrome:\n",
    "    \"\"\"\n",
    "    Initializes and returns a Chrome WebDriver instance with specified options.\n",
    "\n",
    "    Returns:\n",
    "        - webdriver.Chrome: An instance of Chrome WebDriver with specified options.\n",
    "    \"\"\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-search-engine-choice-screen\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    return driver\n",
    "\n",
    "def accept_cookies(driver : webdriver.Chrome) -> None:\n",
    "    \"\"\"\n",
    "    Accepts cookies on a webpage using the provided WebDriver instance.\n",
    "\n",
    "    Parameters:\n",
    "        - driver (webdriver.Chrome): The WebDriver instance used to interact with the webpage.\n",
    "    \"\"\"\n",
    "    cookie_button = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, '//*[@id=\"CybotCookiebotDialogBodyLevelButtonLevelOptinAllowAll\"]'))\n",
    "    )\n",
    "    cookie_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# World records web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(content : str, csv_name : str) -> None:\n",
    "    \"\"\"\n",
    "    Extracts athletic records from HTML and saves to a CSV.\n",
    "\n",
    "    Parameters:\n",
    "        - content (str): HTML content.\n",
    "        - csv_name (str): Output CSV file name.\n",
    "    \"\"\"\n",
    "\n",
    "    # Parse the page content with BeautifulSoup\n",
    "    soup = BeautifulSoup(content, 'html.parser').prettify()\n",
    "    soup = BeautifulSoup(soup, 'html.parser')\n",
    "\n",
    "    # Find the table containing the records\n",
    "    table_body = soup.find(attrs={'class':'Table_table__2zsdR RecordsTable_table__3X8lL'}).find('tbody')\n",
    "    # Find all table rows\n",
    "    rows = table_body.find_all('tr')\n",
    "\n",
    "    data = {\n",
    "        'DISCIPLINE': [],\n",
    "        'PERF': [],\n",
    "        'COMPETITOR': [],\n",
    "        'DOB': [],\n",
    "        'COUNTRY': [],\n",
    "        'VENUE': [],\n",
    "        'DATE': []\n",
    "    }\n",
    "\n",
    "    for row in rows:\n",
    "        cells = row.find_all('td')\n",
    "        data['DISCIPLINE'].append(cells[0].text.strip())\n",
    "        \n",
    "        perf = cells[2].text.strip()\n",
    "        for r in [\"*\", \"Mx\", \"Wo\", \"h\"]:\n",
    "            perf = perf.replace(r, \"\")\n",
    "        data['PERF'].append(perf.strip())\n",
    "\n",
    "        data['COMPETITOR'].append(cells[4].text.strip())\n",
    "        data['DOB'].append(cells[5].text.strip())\n",
    "        data['COUNTRY'].append(cells[6].text.strip())\n",
    "        data['VENUE'].append(cells[7].text.strip().replace(\"(i)\", \"\"))\n",
    "        data['DATE'].append(cells[8].text.strip())\n",
    "\n",
    "    records = pd.DataFrame(data)\n",
    "    records.to_csv(csv_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_world_records() -> None:\n",
    "    driver = initialize_driver()\n",
    "    \n",
    "    try:\n",
    "        driver.get(\"https://worldathletics.org/records/by-category/world-records\")\n",
    "        accept_cookies(driver)\n",
    "        \n",
    "        create_csv(driver.page_source, \"data/women_world_records.csv\")\n",
    "        \n",
    "        men_button = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//*[@id=\"__next\"]/div[3]/div/div/div[2]/ul/li[2]/button'))\n",
    "        )\n",
    "        men_button.click()\n",
    "        \n",
    "        create_csv(driver.page_source, \"data/men_world_records.csv\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "scrape_world_records()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Top 100 Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(content: str, year: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts athletic TOP100 performances from HTML and saves to a CSV.\n",
    "\n",
    "    Parameters:\n",
    "        - content (str): HTML content.\n",
    "        - year (int): Year of the TOP100 performances.\n",
    "    \"\"\"\n",
    "\n",
    "    soup = BeautifulSoup(content, 'html.parser').prettify()\n",
    "    soup = BeautifulSoup(soup, 'html.parser')\n",
    "    table_body = soup.find(attrs={'class':'records-table'})\n",
    "\n",
    "    if table_body is None:\n",
    "        raise ValueError(\"The data for the specified year is not available, please try another year.\")\n",
    "\n",
    "    rows = table_body.find_all('tr')\n",
    "\n",
    "    data = {\n",
    "        'YEAR': [],\n",
    "        'RANK': [],\n",
    "        'MARK': [],\n",
    "        'WIND': [],\n",
    "        'COMPETITOR': [],\n",
    "        'DOB': [],\n",
    "        'COUNTRY': [],\n",
    "        'POS': [],\n",
    "        'VENUE': [],\n",
    "        'DATE': [],\n",
    "        'SCORE': [],\n",
    "    }\n",
    "\n",
    "    for row in rows[1:]:\n",
    "        cells = row.find_all('td')\n",
    "        data['YEAR'].append(year)\n",
    "        data['RANK'].append(int(cells[0].get_text(strip=True)))\n",
    "        data['MARK'].append(cells[1].get_text(strip=True))\n",
    "        wind = cells[2].get_text(strip=True)\n",
    "        data['WIND'].append(float(wind) if wind != \"\" else None)\n",
    "        data['COMPETITOR'].append(cells[3].get_text(strip=True))\n",
    "        data['DOB'].append(cells[4].text.strip())\n",
    "        data['COUNTRY'].append(cells[5].text.strip())\n",
    "        data['POS'].append(cells[6].text.strip())\n",
    "        data['VENUE'].append(cells[8].text.strip())\n",
    "        data['DATE'].append(cells[9].text.strip())\n",
    "        data['SCORE'].append(int(cells[10].text.strip()))\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def scrape_year(year: int,\n",
    "                sex: str = \"men\",\n",
    "                event: str = \"marathon\",\n",
    "                num_page: int = 1,\n",
    "                bestResultsOnly: bool = False,\n",
    "                maxResultsByCountry: Union[str, int] = \"all\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Scrape athletics performance data from the World Athletics website for a given year, sex, and event.\n",
    "\n",
    "    Parameters:\n",
    "        - year (int) : The year for which to scrape the data.\n",
    "\n",
    "        - sex (str, optional) : The sex category for the event. Can be \"men\" or \"women\". Default is \"men\".\n",
    "\n",
    "        - event (str, optional) : The athletics event to scrape. Default is \"marathon\". Allowed events are: \"50-metres\", \"100-metres\"\n",
    "        \"200-metres\", \"400-metres\", \"800-metres\", \"1500-metres\", \"3000-metres\", \"5000-metres\", \"10000-metres\", \"5-kilometres\", \"10-kilometres\",\n",
    "        \"half-marathon\", \"marathon\"\n",
    "\n",
    "        - num_page (int, optional) : The number of pages to scrape. Default is 1.\n",
    "    \n",
    "        - bestResultsOnly (bool, optional) : Whether to scrape only the best results. Default is False.\n",
    "    \n",
    "        - maxResultsByCountry (Union[str, int], optional) :The maximum number of results by country. Can be \"all\" or an integer between 1 and 5.\n",
    "        Default is \"all\".\n",
    "\n",
    "    Returns:\n",
    "        - pd.DataFrame : A DataFrame containing the scraped data.\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    >>> df = scrape_year(2023, sex=\"women\", event=\"100-metres\", num_page=2, bestResultsOnly=True, maxResultsByCountry=3)\n",
    "    >>> print(df.head())\n",
    "    \"\"\"\n",
    "    \n",
    "    ########## Validate input\n",
    "    category = {\n",
    "    \"50-metres\": \"sprints\", \"100-metres\": \"sprints\", \"200-metres\": \"sprints\", \"400-metres\": \"sprints\", \"800-metres\": \"middlelong\",\n",
    "    \"1500-metres\": \"middlelong\", \"3000-metres\": \"middlelong\", \"5000-metres\": \"middlelong\", \"10000-metres\": \"middlelong\",\n",
    "    \"5-kilometres\": \"road-running\", \"10-kilometres\": \"road-running\", \"half-marathon\": \"road-running\", \"marathon\": \"road-running\",\n",
    "    }\n",
    "\n",
    "    if event not in category:\n",
    "        allowed_events = \", \".join(category.keys())\n",
    "        raise ValueError(f\"Invalid event: {event}. Allowed events are: {allowed_events}\")\n",
    "    \n",
    "    bestResultsOnly = \"true\" if bestResultsOnly else \"false\"\n",
    "\n",
    "    if not (maxResultsByCountry == \"all\" or (isinstance(maxResultsByCountry, int) and 1 <= maxResultsByCountry <= 5)):\n",
    "        raise ValueError(\"maxResultsByCountry must be 'all' or an integer between 1 and 5\")\n",
    "    ##########\n",
    "\n",
    "    driver = initialize_driver()\n",
    "    all_data = pd.DataFrame()\n",
    "\n",
    "    for page in range(1, num_page + 1):\n",
    "        url = f\"https://worldathletics.org/records/toplists/{category[event]}/{event}/all/{sex}/senior/{year}?regionType=world&page={page}&bestResultsOnly={bestResultsOnly}&maxResultsByCountry={maxResultsByCountry}&ageCategory=senior\"\n",
    "        driver.get(url)\n",
    "        if page == 1:\n",
    "            accept_cookies(driver)\n",
    "        df = create_csv(driver.page_source, year)\n",
    "        all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "    \n",
    "    driver.quit()\n",
    "    return all_data\n",
    "\n",
    "# Example usage\n",
    "# df = scrape_year(2019, sex = \"men\", event = \"50-metres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_list = [\"men\", \"women\"]\n",
    "disciplines_list = [\"50-metres\", \"100-metres\", \"200-metres\", \"400-metres\", \"800-metres\", \"1500-metres\", \"3000-metres\",\n",
    "                    \"5000-metres\", \"10000-metres\", \"10-kilometres\", \"half-marathon\", \"marathon\"]\n",
    "\n",
    "all_data = pd.DataFrame(columns=['YEAR', 'SEX', 'DISCIPLINE', 'RANK', 'MARK', 'WIND', 'COMPETITOR', 'DOB', 'COUNTRY', 'POS', 'VENUE', 'DATE', 'SCORE'])\n",
    "\n",
    "for discipline in disciplines_list:\n",
    "    for sex in sex_list:\n",
    "        for year in range(2001, 2025):\n",
    "            print(f\"Scraping {sex}, {discipline}, {year}\")\n",
    "            yearly_data = scrape_year(year, sex, discipline)\n",
    "            if not yearly_data.empty:\n",
    "                yearly_data['YEAR'], yearly_data['SEX'], yearly_data['DISCIPLINE'] = year, sex, discipline\n",
    "                yearly_data = yearly_data[['YEAR', 'SEX', 'DISCIPLINE'] + [col for col in yearly_data.columns if col not in ['YEAR', 'SEX', 'DISCIPLINE']]]\n",
    "                all_data = pd.concat([all_data, yearly_data], ignore_index=True)\n",
    "\n",
    "all_data.to_csv(\"data/top100_all_2001_2024.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
